"""
FujiShaderGPU/config/system_config.py
"""

import math, multiprocessing, psutil
import cupy as cp
from typing import Optional, List
from osgeo import gdal

def get_gpu_config(gpu_type: str = "auto", sigma: float = 10.0, multiscale_mode: bool = True, pixel_size: float = 0.5, target_distances: Optional[List[float]] = None) -> dict:
    """
    GPUç¨®åˆ¥ã«å¿œã˜ãŸæœ€é©è¨­å®šã‚’å–å¾—ï¼ˆT4/L4å¯¾å¿œå®‰å®šç‰ˆï¼‰
    """
    sys_config = detect_optimal_system_config()
    
    if gpu_type == "auto":
        gpu_name = sys_config.get("gpu_name", "").upper()
        vram_gb = sys_config["vram_gb"]
        
        # GPUåã«ã‚ˆã‚‹è©³ç´°åˆ¤å®š
        if "A100" in gpu_name or vram_gb >= 40:
            gpu_type = "a100"
        elif "L4" in gpu_name or (vram_gb >= 20 and vram_gb < 32):
            gpu_type = "l4"
        elif "T4" in gpu_name or (vram_gb >= 14 and vram_gb < 20):
            gpu_type = "t4"
        elif "RTX 4070" in gpu_name or (vram_gb >= 8 and vram_gb < 14):
            gpu_type = "rtx4070"
        else:
            gpu_type = "rtx4070"  # å®‰å…¨å´è¨­å®š
            
        print(f"GPUè‡ªå‹•æ¤œå‡º: {gpu_name} ({vram_gb:.1f}GB) â†’ {gpu_type}è¨­å®š")
    
    # Ïƒå€¤ã¨ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«è¨­å®šã«åŸºã¥ãpaddingè¨ˆç®—
    if multiscale_mode:
        if target_distances is not None:
            max_distance = max(target_distances)
            max_sigma = max_distance / pixel_size
        else:
            default_distances = [5.0, 25.0, 100.0, 200.0]
            max_distance = max(default_distances)
            max_sigma = max_distance / pixel_size
        required_padding = int(math.ceil(max_sigma * 5.0))
    else:
        required_padding = int(math.ceil(sigma * 5.0))
    
    min_padding = 32
    calculated_padding = max(min_padding, ((required_padding + 31) // 32) * 32)
    
    # å®‰å®šç‰ˆè¨­å®šï¼ˆT4/L4ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’å‰Šæ¸›ï¼‰
    configs = {
        "rtx4070": {
            "tile_size": 4096,      # å¤§å¹…å¢—é‡ï¼ˆ2048â†’4096ï¼‰
            "max_workers": min(6, sys_config["cpu_count"]),  # CPUæ•°ã«å¿œã˜ã¦èª¿æ•´
            "padding": calculated_padding,
            "vram_monitor": False,
            "batch_size": 2,        # è¤‡æ•°ã‚¿ã‚¤ãƒ«åŒæ™‚å‡¦ç†
            "prefetch_tiles": 4,    # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒæ•°
            "description": "RTX 4070 è¶…é«˜é€Ÿæœ€é©åŒ–ï¼ˆ4K tilesï¼‰"
        },
        "t4": {
            "tile_size": 2048,      # T4: å®‰å®šæ€§é‡è¦–ï¼ˆ3072â†’2048ï¼‰
            "max_workers": min(6, sys_config["cpu_count"]),  # ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚‚å‰Šæ¸›
            "padding": calculated_padding,
            "vram_monitor": True,   # ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚’æœ‰åŠ¹åŒ–
            "batch_size": 1,        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æœ€å°åŒ–
            "prefetch_tiles": 2,    # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã‚’å¤§å¹…å‰Šæ¸›
            "description": "Tesla T4 å®‰å®šç‰ˆï¼ˆ16GB VRAMã€2K tilesï¼‰"
        },
        "l4": {
            "tile_size": 4096,      # L4: å®‰å®šæ€§é‡è¦–ï¼ˆ6144â†’4096ï¼‰
            "max_workers": min(8, sys_config["cpu_count"]),  # ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã‚‚èª¿æ•´
            "padding": calculated_padding,
            "vram_monitor": True,   # ãƒ¡ãƒ¢ãƒªç›£è¦–ã‚’ç¶­æŒ
            "batch_size": 2,        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’å‰Šæ¸›
            "prefetch_tiles": 4,    # ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã‚’åŠæ¸›
            "description": "L4 å®‰å®šç‰ˆï¼ˆ24GB VRAMã€4K tilesï¼‰"
        },
        "a100": {
            "tile_size": 8192,      # A100ã¯èª¿æ•´æ¸ˆã¿ã§å•é¡Œãªã—
            "max_workers": min(16, sys_config["cpu_count"]),
            "padding": calculated_padding,
            "vram_monitor": True,
            "batch_size": 4,        # ã‚ˆã‚Šå¤šãã®ã‚¿ã‚¤ãƒ«åŒæ™‚å‡¦ç†
            "prefetch_tiles": 8,    # å¤§é‡ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒ
            "description": "A100 è¶…é«˜é€Ÿæœ€é©åŒ–ï¼ˆ8K tiles + batchå‡¦ç†ï¼‰"
        }
    }
    
    config = configs.get(gpu_type, configs["rtx4070"])
    config["system_info"] = sys_config
    
    # Google Colabç’°å¢ƒã§ã®è¿½åŠ èª¿æ•´
    if sys_config.get("is_colab", False):
        if gpu_type == "t4":
            config["tile_size"] = min(config["tile_size"], 2048)
            config["batch_size"] = 1
            print("âš ï¸ Google Colab T4ç’°å¢ƒ: ãƒ¡ãƒ¢ãƒªåˆ¶é™ã®ãŸã‚è¨­å®šã‚’èª¿æ•´")
        elif gpu_type == "l4":
            config["tile_size"] = min(config["tile_size"], 4096)
            config["batch_size"] = min(config["batch_size"], 2)
            print("âš ï¸ Google Colab L4ç’°å¢ƒ: ãƒ¡ãƒ¢ãƒªåˆ¶é™ã®ãŸã‚è¨­å®šã‚’èª¿æ•´")
    
    return config


def detect_optimal_system_config() -> dict:
    """
    ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒã‚’è©³ç´°ã«åˆ†æã—ã¦æœ€é©ãªè¨­å®šã‚’æ±ºå®šï¼ˆå®‰å®šç‰ˆï¼‰
    """
    config = {
        "cpu_count": multiprocessing.cpu_count(),
        "memory_gb": psutil.virtual_memory().total // (1024**3),
        "gpu_detected": False,
        "gpu_name": "Unknown",
        "vram_gb": 0,
        "platform": "unknown"
    }
    
    # GPUè©³ç´°æ¤œå‡º
    try:
        gpu_count = cp.cuda.runtime.getDeviceCount()
        if gpu_count > 0:
            config["gpu_detected"] = True
            gpu_props = cp.cuda.runtime.getDeviceProperties(0)
            config["gpu_name"] = gpu_props['name'].decode()
            config["vram_gb"] = cp.cuda.runtime.memGetInfo()[1] / (1024**3)
            config["gpu_compute_capability"] = f"{gpu_props['major']}.{gpu_props['minor']}"
            config["gpu_multiprocessors"] = gpu_props['multiProcessorCount']
    except:
        pass
    
    # Google Colabæ¤œå‡º
    try:
        import google.colab
        config["platform"] = "colab"
        config["is_colab"] = True
    except ImportError:
        config["platform"] = "local"
        config["is_colab"] = False
    
    # æœ€é©åŒ–ãƒ¬ãƒ™ãƒ«æ±ºå®šï¼ˆT4/L4å¯¾å¿œï¼‰
    if config["vram_gb"] >= 40:  # A100ã‚¯ãƒ©ã‚¹
        config["optimization_level"] = "ultra"
    elif config["vram_gb"] >= 20:  # L4ã‚¯ãƒ©ã‚¹
        config["optimization_level"] = "high"  # very_high â†’ high ã«ä¸‹ã’ã‚‹
    elif config["vram_gb"] >= 14:  # T4ã‚¯ãƒ©ã‚¹
        config["optimization_level"] = "medium"  # high â†’ medium ã«ä¸‹ã’ã‚‹
    elif config["vram_gb"] >= 8:   # RTX4070ã‚¯ãƒ©ã‚¹
        config["optimization_level"] = "medium_high"
    else:
        config["optimization_level"] = "standard"
    
    print(f"ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆæ¤œå‡º:")
    print(f"  CPU: {config['cpu_count']}ã‚³ã‚¢, RAM: {config['memory_gb']}GB")
    if config["gpu_detected"]:
        print(f"  GPU: {config['gpu_name']}, VRAM: {config['vram_gb']:.1f}GB")
        print(f"  æœ€é©åŒ–ãƒ¬ãƒ™ãƒ«: {config['optimization_level']}")
    
    return config


def check_gdal_environment():
    """
    GDALç’°å¢ƒãƒã‚§ãƒƒã‚¯ï¼ˆQGISæœ€é©åŒ–å¯¾å¿œï¼‰
    """
    print("=== GDALç’°å¢ƒãƒã‚§ãƒƒã‚¯ ===")
    
    gdal_version = gdal.VersionInfo()
    print(f"GDALãƒãƒ¼ã‚¸ãƒ§ãƒ³: {gdal_version}")
    
    cog_driver = gdal.GetDriverByName("COG")
    print(f"COGãƒ‰ãƒ©ã‚¤ãƒãƒ¼: {'âœ… åˆ©ç”¨å¯èƒ½' if cog_driver else 'âŒ åˆ©ç”¨ä¸å¯'}")
    
    gtiff_driver = gdal.GetDriverByName("GTiff")
    print(f"GTiffãƒ‰ãƒ©ã‚¤ãƒãƒ¼: {'âœ… åˆ©ç”¨å¯èƒ½' if gtiff_driver else 'âŒ åˆ©ç”¨ä¸å¯'}")
    
    # QGISæœ€é©åŒ–æƒ…å ±
    print("\nğŸ¯ QGISæœ€é©åŒ–:")
    print("   - 512x512ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º")
    print("   - å¤šæ®µéšã‚ªãƒ¼ãƒãƒ¼ãƒ“ãƒ¥ãƒ¼ï¼ˆ2-512ãƒ¬ãƒ™ãƒ«ï¼‰")
    print("   - AVERAGE ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°")
    print("   - ZSTDé«˜é€Ÿåœ§ç¸®")
    
    # ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆè¡¨ç¤º
    sys_config = detect_optimal_system_config()
    print("=" * 50)