"""
FujiShaderGPU/config/system_config.py
"""

import math, multiprocessing, psutil, logging
import cupy as cp
from typing import Optional, List
from osgeo import gdal
from ..config.gpu_config_manager import _gpu_config_manager

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logger = logging.getLogger(__name__)

def get_gpu_config(gpu_type: str = "auto", sigma: float = 10.0, multiscale_mode: bool = True, 
                   pixel_size: float = 0.5, target_distances: Optional[List[float]] = None) -> dict:
    """GPUç¨®åˆ¥ã«å¿œã˜ãŸæœ€é©è¨­å®šã‚’å–å¾—ï¼ˆT4/L4å¯¾å¿œå®‰å®šç‰ˆï¼‰"""
    sys_config = detect_optimal_system_config()
    
    if gpu_type == "auto":
        gpu_name = sys_config.get("gpu_name", "").upper()
        vram_gb = sys_config["vram_gb"]
        gpu_type = _gpu_config_manager.detect_gpu_type(vram_gb, gpu_name)
        print(f"GPUè‡ªå‹•æ¤œå‡º: {gpu_name} ({vram_gb:.1f}GB) â†’ {gpu_type}è¨­å®š")
    
    # ãƒ—ãƒªã‚»ãƒƒãƒˆã‹ã‚‰è¨­å®šã‚’å–å¾—
    preset = _gpu_config_manager.get_preset(gpu_type)
    
    # Ïƒå€¤ã¨ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«è¨­å®šã«åŸºã¥ãpaddingè¨ˆç®—
    if multiscale_mode:
        if target_distances is not None:
            max_distance = max(target_distances)
            max_sigma = max_distance / pixel_size
        else:
            default_distances = [5.0, 25.0, 100.0, 200.0]
            max_distance = max(default_distances)
            max_sigma = max_distance / pixel_size
        required_padding = int(math.ceil(max_sigma * 5.0))
    else:
        required_padding = int(math.ceil(sigma * 5.0))
    
    min_padding = 32
    calculated_padding = max(min_padding, ((required_padding + 31) // 32) * 32)
    
    # æ—¢å­˜ã®å½¢å¼ã«å¤‰æ›ï¼ˆäº’æ›æ€§ã®ãŸã‚ï¼‰
    config = {
        "tile_size": preset["chunk_size"] * 2,  # tile_sizeã¯chunk_sizeã®2å€ã¨ã—ã¦æ‰±ã†
        "max_workers": min(6, sys_config["cpu_count"]),
        "padding": calculated_padding,
        "vram_monitor": gpu_type != "a100",
        "batch_size": 2 if gpu_type == "a100" else 1,
        "prefetch_tiles": 4 if gpu_type == "a100" else 2,
        "description": f"{preset.get('name', gpu_type.upper())} æœ€é©åŒ–è¨­å®š",
        "system_info": sys_config,
    }
    
    return config


def detect_optimal_system_config() -> dict:
    """
    ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒã‚’è©³ç´°ã«åˆ†æã—ã¦æœ€é©ãªè¨­å®šã‚’æ±ºå®šï¼ˆå®‰å®šç‰ˆï¼‰
    """
    config = {
        "cpu_count": multiprocessing.cpu_count(),
        "memory_gb": psutil.virtual_memory().total // (1024**3),
        "gpu_detected": False,
        "gpu_name": "Unknown",
        "vram_gb": 0,
        "platform": "unknown"
    }
    
    # GPUè©³ç´°æ¤œå‡º
    try:
        gpu_count = cp.cuda.runtime.getDeviceCount()
        if gpu_count > 0:
            config["gpu_detected"] = True
            gpu_props = cp.cuda.runtime.getDeviceProperties(0)
            config["gpu_name"] = gpu_props['name'].decode()
            config["vram_gb"] = cp.cuda.runtime.memGetInfo()[1] / (1024**3)
            config["gpu_compute_capability"] = f"{gpu_props['major']}.{gpu_props['minor']}"
            config["gpu_multiprocessors"] = gpu_props['multiProcessorCount']
    except (cp.cuda.runtime.CUDARuntimeError, AttributeError) as e:
        logger.debug(f"GPU detection failed: {e}")
        raise RuntimeError("GPU detection failed")
    
    # Google Colabæ¤œå‡º
    try:
        import google.colab
        config["platform"] = "colab"
        config["is_colab"] = True
    except ImportError:
        config["platform"] = "local"
        config["is_colab"] = False
    
    # æœ€é©åŒ–ãƒ¬ãƒ™ãƒ«æ±ºå®šï¼ˆT4/L4å¯¾å¿œï¼‰
    if config["vram_gb"] >= 40:  # A100ã‚¯ãƒ©ã‚¹
        config["optimization_level"] = "ultra"
    elif config["vram_gb"] >= 20:  # L4ã‚¯ãƒ©ã‚¹
        config["optimization_level"] = "high"  # very_high â†’ high ã«ä¸‹ã’ã‚‹
    elif config["vram_gb"] >= 14:  # T4ã‚¯ãƒ©ã‚¹
        config["optimization_level"] = "medium"  # high â†’ medium ã«ä¸‹ã’ã‚‹
    elif config["vram_gb"] >= 8:   # RTX4070ã‚¯ãƒ©ã‚¹
        config["optimization_level"] = "medium_high"
    else:
        config["optimization_level"] = "standard"
    
    print(f"ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆæ¤œå‡º:")
    print(f"  CPU: {config['cpu_count']}ã‚³ã‚¢, RAM: {config['memory_gb']}GB")
    if config["gpu_detected"]:
        print(f"  GPU: {config['gpu_name']}, VRAM: {config['vram_gb']:.1f}GB")
        print(f"  æœ€é©åŒ–ãƒ¬ãƒ™ãƒ«: {config['optimization_level']}")
    
    return config


def check_gdal_environment():
    """
    GDALç’°å¢ƒãƒã‚§ãƒƒã‚¯ï¼ˆQGISæœ€é©åŒ–å¯¾å¿œï¼‰
    """
    print("=== GDALç’°å¢ƒãƒã‚§ãƒƒã‚¯ ===")
    
    gdal_version = gdal.VersionInfo()
    print(f"GDALãƒãƒ¼ã‚¸ãƒ§ãƒ³: {gdal_version}")
    
    cog_driver = gdal.GetDriverByName("COG")
    print(f"COGãƒ‰ãƒ©ã‚¤ãƒãƒ¼: {'âœ… åˆ©ç”¨å¯èƒ½' if cog_driver else 'âŒ åˆ©ç”¨ä¸å¯'}")
    
    gtiff_driver = gdal.GetDriverByName("GTiff")
    print(f"GTiffãƒ‰ãƒ©ã‚¤ãƒãƒ¼: {'âœ… åˆ©ç”¨å¯èƒ½' if gtiff_driver else 'âŒ åˆ©ç”¨ä¸å¯'}")
    
    # QGISæœ€é©åŒ–æƒ…å ±
    print("\nğŸ¯ QGISæœ€é©åŒ–:")
    print("   - 512x512ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º")
    print("   - å¤šæ®µéšã‚ªãƒ¼ãƒãƒ¼ãƒ“ãƒ¥ãƒ¼ï¼ˆ2-512ãƒ¬ãƒ™ãƒ«ï¼‰")
    print("   - AVERAGE ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°")
    print("   - ZSTDé«˜é€Ÿåœ§ç¸®")
    
    # ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆè¡¨ç¤º
    sys_config = detect_optimal_system_config()
    print("=" * 50)